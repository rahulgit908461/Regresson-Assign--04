{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08a0561b-7b1d-4fd3-ad54-c2af4849fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae9f0fdf-a116-4bba-b586-aaff286e8918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso regression is a regularization technique. It is used over regression methods for a more accurate prediction. \n",
    "#It is similar to the Ridge Regression except that penalty term contains only the absolute weights instead of a square of\n",
    "#weights. Since it takes absolute values, hence, it can shrink the slope to 0, whereas Ridge Regression can only shrink it \n",
    "#near to 0. It is also called as L1 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050165b4-69d9-46b2-b9e8-dd3fab759300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cee4d69-4cab-492d-bfeb-d5c8d7976659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The main advantage of a LASSO regression model is that it has the ability to set the coefficients for features it does not \n",
    "#consider interesting to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea18dfea-8237-4efb-b87e-3e1b8a904c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1569c4df-0005-40a7-8a31-091c9ebcab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A positive coefficient indicates that as the value of the independent variable increases, the mean of the dependent variable \n",
    "#also tends to increase. A negative coefficient suggests that as the independent variable increases, the dependent variable tends\n",
    "#to decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f729f0d1-0fcd-4021-9781-6de85916fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "#model's performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ab6588-1936-40ca-86c0-bde1a7085a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A tuning parameter (Î»), sometimes called a penalty parameter, controls the strength of the penalty term in ridge regression \n",
    "#and lasso regression. It is basically the amount of shrinkage, where data values are shrunk towards a central point, \n",
    "#like the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a12d88d-e4bc-4dd4-81f8-244dc89be4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The ordinary lasso penalty has been extensively used in the framework of linear regression models; however, sufficient \n",
    "#results have not been obtained for nonlinear regression models with Gaussian basis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ed9f5c-0bdd-41dd-a919-97cc14ef58d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ec802e0-1c29-441a-814a-0a58c73a5403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar to the lasso regression, ridge regression puts a similar constraint on the coefficients by introducing a penalty \n",
    "#factor. However, while lasso regression takes the magnitude of the coefficients, ridge regression takes the square. Ridge \n",
    "#regression is also referred to as L2 Regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc2418b2-bd38-4306-80fd-2d7cdb7a8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "181aa6e9-1338-44c4-9df3-5ec184123550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another Tolerant Method for dealing with multicollinearity known as Least Absolute Shrinkage and Selection Operator (LASSO) \n",
    "#regression, solves the same constrained optimization problem as ridge regression, but uses the L1 norm rather than the L2 norm \n",
    "#as a measure of complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23086865-75cd-4a36-97c5-c94f779943d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c29b8-a01d-4671-ab49-6ce04c58dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When choosing a lambda value, the goal is to strike the right balance between simplicity and training-data fit: If your lambda value is too high, your model will be simple, but you run the risk of underfitting your data. Your model won't learn enough about the training data to make useful predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
